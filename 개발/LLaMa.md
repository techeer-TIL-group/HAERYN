최근 이탈리아에서 챗GPT를 금지하는 법안을 개정했다.<br>
인공지능이 편향된 자료를 수집하여 대답할 수 있고, <br>
자료 수집 및 이용에 불법적인 요소도 있을 수 있다는 점이 그 근거였다.<br>
이것이 일자리를 뺏어간다는 우려 또한 심상치 않다.<br>
그리고 이러한 진일보된 기술을 한 회사가 독점하면 안 된다는 주장도 있다.<br>
<br>
​
여기서 주목하는 할 점은 독점.<br>
즉, 이러한 인공지능은 인류 전체를 위해서 사용되어야 선순환 구조가 작동되는 것이다.<br>
<br>

챗GPT는 오픈 소스를 바탕으로 개발을 시작했다. <br>
최근에는 완전한 공개를 원칙으로 하는  라마(LLaMa)가 출시되었는데, <br>
무려 ChatGPT3.5 성능에 버금가는 녀석을 이제 누구나 컴퓨터에다가 깔 수 있다. <br>

​
메타의 라마를 비롯해 마이크로소프트의 챗GPT(ChatGPT)의 공통점이 있다. <br>
대규모 언어 모델(LLM)이라는 점이다. <br>
다만, 라마는 챗GPT와는 달리 대중들에게 열려있는 시스템이 아닌, 연구자들로 이용 대상이 한정된다. <br>
해당 언어 모델은 연구자가 AI 언어 모델의 문제점을 파악하고 연구를 돕는 역할을 한다. <br>
<br>
​
문제를 해결하고 답을 찾거나 자체적으로 구성된 답변을 생성할 만큼 정교한 AI 모델을 위해선 <br>
컴퓨터 코드, 유전 데이터를 비롯한 기타 언어의 방대한 데이터가 요구된다. <br>
하지만 라마는 기존의 대규모 언어 모델들과는 달리, 상대적으로 작은 규모의 데이터를 필요로 한다. <br>
<br>

이렇듯 상대적으로 작은 대규모 언어 모델의 학습을 위해 메타는 전체 단어가 아닌, 단어 조각 토큰을 사용했다. <br>
실제 라마 65B 버전과 라마 33B 버전은 1조 4000억 개의 토큰으로 훈련됐다. <br>
라마는 다른 AI 기반 챗봇과 마찬가지로 텍스트 입력 프롬프트에서 사람과 같은 대화를 생성할 수 있다. <br>
메타는 매개변수 범위가 70억에서 650억에 이르는 라마의 4가지 모델을 소개했다. <br>
이를 통해 메타는 보다 정확한 답변을 제시할 수 있는 AI 언어 모델의 연구를 지원할 예정이다.<br>